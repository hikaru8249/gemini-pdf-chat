import streamlit as st
import os
import tempfile
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.gemini import Gemini
from llama_index.embeddings.gemini import GeminiEmbedding
from dotenv import load_dotenv
from streamlit_pdf_viewer import pdf_viewer

# 1. ç’°å¢ƒè¨­å®š
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="å¤šæ©Ÿèƒ½ PDF RAG Chat", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– å¤šæ©Ÿèƒ½ PDF RAG Chatbot (Multi-PDFç‰ˆ)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š & ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")

    if not GOOGLE_API_KEY:
        GOOGLE_API_KEY = st.text_input("Google API Key", type="password")

    if not GOOGLE_API_KEY:
        st.warning("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        st.stop()

    try:
        Settings.llm = Gemini(
            model="models/gemini-3-flash-preview", 
            api_key=GOOGLE_API_KEY, 
            temperature=0.3
        )
        Settings.embed_model = GeminiEmbedding(
            model_name="models/text-embedding-004", 
            api_key=GOOGLE_API_KEY
        )
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    st.subheader("ğŸ“‚ PDFã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ (è¤‡æ•°å¯)")
    # â˜…å¤‰æ›´ç‚¹1: accept_multiple_files=True ã«ã—ã¦è¤‡æ•°é¸æŠã‚’è¨±å¯
    uploaded_files = st.file_uploader(
        "ã“ã“ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ­ãƒƒãƒ—", 
        type=["pdf"], 
        accept_multiple_files=True
    )

    st.subheader("ğŸ“ AIã¸ã®æŒ‡ç¤º")
    system_prompt = st.text_area(
        "AIã®å½¹å‰²",
        value="ã‚ãªãŸã¯æä¾›ã•ã‚ŒãŸè¤‡æ•°ã®PDFã®å†…å®¹ã«åŸºã¥ã„ã¦ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
        height=150
    )

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.button("ğŸ—‘ï¸ ä¼šè©±ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.session_state.last_source_nodes = []
        st.rerun()

# --- é–¢æ•°å®šç¾© ---

@st.cache_resource(show_spinner=False)
def create_index_from_uploaded_files(uploaded_files):
    with st.spinner(f"ğŸš€ {len(uploaded_files)}ã¤ã®PDFã‚’å­¦ç¿’ä¸­..."):
        file_paths = []
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸå…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ™‚ä¿å­˜
        for uploaded_file in uploaded_files:
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                file_paths.append(tmp_file.name)

        # è¤‡æ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã¾ã¨ã‚ã¦èª­ã¿è¾¼ã‚€
        documents = SimpleDirectoryReader(input_files=file_paths).load_data()
        index = VectorStoreIndex.from_documents(documents)
        
        # æƒé™¤
        for path in file_paths:
            os.remove(path)
            
        return index

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---

if "messages" not in st.session_state:
    st.session_state.messages = []

if "last_source_nodes" not in st.session_state:
    st.session_state.last_source_nodes = []

if uploaded_files:
    col1, col2 = st.columns([1, 1])

    # --- å³ã‚«ãƒ©ãƒ ï¼šPDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (åˆ‡ã‚Šæ›¿ãˆæ©Ÿèƒ½ä»˜ã) ---
    with col2:
        st.subheader("ğŸ“„ PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        
        # â˜…å¤‰æ›´ç‚¹2: ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã™ã‚‹ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’ä½œæˆ
        # ãƒ•ã‚¡ã‚¤ãƒ«åã®ãƒªã‚¹ãƒˆã‚’ä½œæˆ
        file_names = [f.name for f in uploaded_files]
        selected_file_name = st.selectbox("ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ:", file_names)
        
        # é¸æŠã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        selected_file = next(f for f in uploaded_files if f.name == selected_file_name)
        
        # è¡¨ç¤º
        pdf_viewer(input=selected_file.getvalue(), height=800)

    # --- å·¦ã‚«ãƒ©ãƒ ï¼šãƒãƒ£ãƒƒãƒˆ ---
    with col1:
        st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
        
        try:
            # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å¯¾å¿œã®é–¢æ•°ã‚’å‘¼ã³å‡ºã—
            index = create_index_from_uploaded_files(uploaded_files)
            query_engine = index.as_query_engine()

            # å±¥æ­´è¡¨ç¤º
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            # AIå›ç­”ç”Ÿæˆ
            if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                with st.chat_message("assistant"):
                    with st.spinner("AIãŒè¤‡æ•°ã®è³‡æ–™ã‹ã‚‰æ€è€ƒä¸­..."):
                        last_user_msg = st.session_state.messages[-1]["content"]
                        final_prompt = f"{system_prompt}\n\n---\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {last_user_msg}"
                        
                        response = query_engine.query(final_prompt)
                        st.markdown(response.response)
                        
                        st.session_state.last_source_nodes = response.source_nodes
                    
                    # ã‚½ãƒ¼ã‚¹è¡¨ç¤ºï¼ˆã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆä¿®æ­£æ¸ˆã¿ï¼‰
                    if st.session_state.last_source_nodes:
                        with st.expander("ğŸ” å›ç­”ã®æ ¹æ‹ ï¼ˆã‚½ãƒ¼ã‚¹ï¼‰ã‚’ç¢ºèªã™ã‚‹"):
                            for node in st.session_state.last_source_nodes:
                                # ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ä½•ãƒšãƒ¼ã‚¸ã‹ã‚’è¡¨ç¤º
                                file_name = node.metadata.get("file_name", "ä¸æ˜")
                                page_label = node.metadata.get("page_label", "ä¸æ˜")
                                score = f"{node.score:.2f}" if node.score else "N/A"
                                
                                st.markdown(f"**ğŸ“„ {file_name} - P.{page_label} (é¡ä¼¼åº¦: {score})**")
                                st.info(node.text[:200] + "...") 
                                st.markdown("---")
                
                st.session_state.messages.append({"role": "assistant", "content": response.response})

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # å…¥åŠ›æ¬„
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        st.session_state.last_source_nodes = []
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

else:
    st.info("ğŸ‘ˆ å·¦å´ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ï¼ˆè¤‡æ•°é¸æŠå¯ï¼‰ã€‚")