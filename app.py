import streamlit as st
import os
import tempfile
import datetime
import pandas as pd
import docx2txt
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from dotenv import load_dotenv
from streamlit_pdf_viewer import pdf_viewer
import openpyxl

# â˜…å¤‰æ›´ç‚¹: ä½œæˆã—ãŸ models.py ã‹ã‚‰é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from models import get_llm_model, get_embed_model

# 1. ç’°å¢ƒè¨­å®š
load_dotenv()
env_api_key = os.getenv("GOOGLE_API_KEY")

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(page_title="å¤šæ©Ÿèƒ½ RAG Chat", page_icon="ğŸ¤–", layout="wide")

st.title("ğŸ¤– å¤šæ©Ÿèƒ½ ãƒãƒ«ãƒãƒ•ã‚¡ã‚¤ãƒ« RAG Chatbot")

# --- é–¢æ•°å®šç¾©: CSSèª­ã¿è¾¼ã¿ ---
def load_css(file_name):
    # Windowså¯¾å¿œ: utf-8æŒ‡å®š
    with open(file_name, encoding="utf-8") as f:
        st.markdown(f"<style>{f.read()}</style>", unsafe_allow_html=True)

try:
    load_css("style.css")
except FileNotFoundError:
    st.warning("âš ï¸ style.css ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")

# --- é–¢æ•°å®šç¾©: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ ---
@st.cache_resource(show_spinner=False)
def create_index_from_uploaded_files(uploaded_files):
    with st.spinner(f"ğŸš€ {len(uploaded_files)}ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å­¦ç¿’ä¸­..."):
        file_paths = []
        for uploaded_file in uploaded_files:
            uploaded_file.seek(0)
            file_ext = os.path.splitext(uploaded_file.name)[1].lower()
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
            with tempfile.NamedTemporaryFile(delete=False, suffix=file_ext) as tmp_file:
                # CSVæ–‡å­—ã‚³ãƒ¼ãƒ‰å¯¾ç­–
                if file_ext == ".csv":
                    try:
                        df = pd.read_csv(uploaded_file)
                    except UnicodeDecodeError:
                        uploaded_file.seek(0)
                        df = pd.read_csv(uploaded_file, encoding='shift_jis')
                    
                    # UTF-8 ã§ä¿å­˜ã—ç›´ã™
                    df.to_csv(tmp_file.name, index=False, encoding='utf-8')
                    file_paths.append(tmp_file.name)
                
                else:
                    tmp_file.write(uploaded_file.getvalue())
                    file_paths.append(tmp_file.name)

        # LlamaIndexã§èª­ã¿è¾¼ã¿
        documents = SimpleDirectoryReader(input_files=file_paths).load_data()
        index = VectorStoreIndex.from_documents(documents)
        
        for path in file_paths:
            os.remove(path)
            
        return index

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []

if "last_source_nodes" not in st.session_state:
    st.session_state.last_source_nodes = []

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
with st.sidebar:
    st.title("ğŸ•¹ï¸ ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«")
    
    st.subheader("1. è³‡æ–™ã®è¿½åŠ ")
    uploaded_files = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°", 
        type=["pdf", "docx", "txt", "md", "csv", "xlsx", "png", "jpg", "jpeg"], 
        accept_multiple_files=True
    )
    
    st.markdown("---")

    with st.expander("âš™ï¸ è¨­å®š (API Key)", expanded=False):
        user_input_key = st.text_input("API Key", type="password", key="user_api_input")
        st.caption("AIã®å½¹å‰²")
        system_prompt = st.text_area(
            "ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ",
            value="ã‚ãªãŸã¯æä¾›ã•ã‚ŒãŸè³‡æ–™ã®å†…å®¹ã«åŸºã¥ã„ã¦ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
            height=100
        )

    active_api_key = user_input_key if user_input_key else env_api_key

    if not active_api_key:
        st.error("ğŸ‘ˆ APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        st.stop()

    # --- ãƒ¢ãƒ‡ãƒ«è¨­å®š (models.py ã‹ã‚‰èª­ã¿è¾¼ã¿) ---
    try:
        # models.py ã§å®šç¾©ã—ãŸé–¢æ•°ã‚’ä½¿ç”¨
        llm = get_llm_model(active_api_key)
        embed_model = get_embed_model(active_api_key)
        
        Settings.llm = llm
        Settings.embed_model = embed_model
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    st.subheader("2. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    col_btn1, col_btn2, col_btn3 = st.columns(3)

    with col_btn1:
        if st.button("ğŸ“", help="ä¼šè©±å±¥æ­´ã‚’è¦ç´„", use_container_width=True):
            if not st.session_state.messages:
                st.warning("å±¥æ­´ãªã—")
            else:
                with st.spinner("è¦ç´„ä¸­..."):
                    chat_history = "\n".join([f"{'ãƒ¦ãƒ¼ã‚¶ãƒ¼' if m['role']=='user' else 'AI'}: {m['content']}" for m in st.session_state.messages])
                    summary_prompt = f"ä»¥ä¸‹ã®ä¼šè©±ã‚’ç®‡æ¡æ›¸ãã§è¦ç´„ã—ã¦:\n\n{chat_history}"
                    try:
                        response = llm.complete(summary_prompt)
                        st.session_state.summary_result = response.text
                    except Exception as e:
                        st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

    with col_btn2:
        if st.button("ğŸ—‘ï¸", help="ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.messages = []
            st.session_state.last_source_nodes = []
            if "summary_result" in st.session_state:
                del st.session_state.summary_result
            st.rerun()
            
    with col_btn3:
        chat_log_str = ""
        for msg in st.session_state.messages:
            role = "User" if msg["role"] == "user" else "AI"
            chat_log_str += f"[{role}] {msg['content']}\n\n"
        
        if "summary_result" in st.session_state:
            chat_log_str += f"\n--- è¦ç´„ ---\n{st.session_state.summary_result}\n"

        now = datetime.datetime.now().strftime("%Y%m%d_%H%M")
        st.download_button(
            label="ğŸ’¾", help="ä¿å­˜",
            data=chat_log_str,
            file_name=f"chat_log_{now}.txt",
            mime="text/plain",
            use_container_width=True
        )

    if "summary_result" in st.session_state:
        st.success(f"**ğŸ’¡ è¦ç´„:**\n\n{st.session_state.summary_result}")

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---

if uploaded_files:
    col1, col2 = st.columns([1, 1])

    # --- ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ ---
    with col2:
        st.subheader("ğŸ“„ è³‡æ–™ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        file_names = [f.name for f in uploaded_files]
        if file_names:
            selected_file_name = st.selectbox("è¡¨ç¤ºã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«:", file_names)
            selected_file = next(f for f in uploaded_files if f.name == selected_file_name)
            selected_file.seek(0)
            
            file_ext = os.path.splitext(selected_file.name)[1].lower()
            try:
                if file_ext == ".pdf":
                    pdf_viewer(input=selected_file.getvalue(), height=800)
                elif file_ext == ".csv":
                    try:
                        df = pd.read_csv(selected_file)
                    except UnicodeDecodeError:
                        selected_file.seek(0)
                        df = pd.read_csv(selected_file, encoding='shift_jis')
                    st.dataframe(df, height=400)
                elif file_ext == ".xlsx":
                    df = pd.read_excel(selected_file)
                    st.dataframe(df, height=400)
                elif file_ext in [".png", ".jpg", ".jpeg"]:
                    st.image(selected_file, caption=selected_file_name, use_container_width=True)
                elif file_ext == ".docx":
                    text = docx2txt.process(selected_file)
                    st.info("â„¹ï¸ Wordãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º")
                    st.text_area("å†…å®¹", text, height=600)
                elif file_ext in [".txt", ".md"]:
                    string_data = selected_file.getvalue().decode("utf-8", errors="ignore")
                    st.text_area("å†…å®¹", string_data, height=600)
                else:
                    st.warning(f"{file_ext} ã¯ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼éå¯¾å¿œ")
            except Exception as e:
                st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")

    # --- ãƒãƒ£ãƒƒãƒˆ ---
    with col1:
        st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
        try:
            index = create_index_from_uploaded_files(uploaded_files)
            
            # CSVãªã©çŸ­ã„ãƒ‡ãƒ¼ã‚¿ç”¨ã« similarity_top_k ã‚’å¤šã‚ã«è¨­å®š
            query_engine = index.as_query_engine(
                streaming=True,
                similarity_top_k=5
            )

            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                with st.chat_message("assistant"):
                    response_placeholder = st.empty()
                    full_response = ""
                    
                    last_user_msg = st.session_state.messages[-1]["content"]
                    final_prompt = f"{system_prompt}\n\n---\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {last_user_msg}"
                    
                    streaming_response = query_engine.query(final_prompt)
                    
                    for token in streaming_response.response_gen:
                        full_response += token
                        response_placeholder.markdown(full_response + "â–Œ")
                    
                    response_placeholder.markdown(full_response)
                    st.session_state.last_source_nodes = streaming_response.source_nodes
                    
                    if st.session_state.last_source_nodes:
                        with st.expander("ğŸ” æ ¹æ‹ ï¼ˆã‚½ãƒ¼ã‚¹ï¼‰"):
                            for node in st.session_state.last_source_nodes:
                                file_name = node.metadata.get("file_name", "ä¸æ˜")
                                page = node.metadata.get("page_label", "-")
                                score = f"{node.score:.2f}" if node.score else "N/A"
                                st.markdown(f"**{file_name} - Score: {score}**")
                                st.info(node.text[:100] + "...")
                                st.markdown("---")
                
                st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›..."):
        st.session_state.last_source_nodes = []
        st.session_state.messages.append({"role": "user", "content": prompt})
        st.rerun()

else:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")