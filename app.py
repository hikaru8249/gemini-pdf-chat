import streamlit as st
import os
import datetime
import io
from llama_index.core import Settings
from llama_index.core.schema import ImageDocument
from dotenv import load_dotenv

# åˆ†å‰²ã—ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
# â€» ui.py, logic.py, models.py ãŒåŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
import ui
import logic
from models import get_llm_model, get_embed_model

# 1. ç’°å¢ƒè¨­å®š
load_dotenv()

# â˜…ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆ: å®‰å…¨ãªAPIã‚­ãƒ¼å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
def get_api_key():
    # 1. ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ› (ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆ)
    if "user_api_input" in st.session_state and st.session_state.user_api_input:
        return st.session_state.user_api_input
    
    # 2. Streamlit Secrets (ã‚¯ãƒ©ã‚¦ãƒ‰ç”¨)
    # ãƒ­ãƒ¼ã‚«ãƒ«ã§ secrets.toml ãŒãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’å›é¿
    try:
        if "GOOGLE_API_KEY" in st.secrets:
            return st.secrets["GOOGLE_API_KEY"]
    except FileNotFoundError:
        pass # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã‘ã‚Œã°ç„¡è¦–
    except Exception:
        pass # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã‚‚ç„¡è¦–

    # 3. ç’°å¢ƒå¤‰æ•° (.env)
    return os.getenv("GOOGLE_API_KEY")

st.set_page_config(page_title="å¤šæ©Ÿèƒ½ RAG Chat", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– å¤šæ©Ÿèƒ½ ãƒãƒ«ãƒãƒ•ã‚¡ã‚¤ãƒ« RAG Chatbot")

# CSSé©ç”¨
ui.load_css("style.css")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆæœŸåŒ–
if "messages" not in st.session_state: st.session_state.messages = []
if "last_source_nodes" not in st.session_state: st.session_state.last_source_nodes = []
if "current_images" not in st.session_state: st.session_state.current_images = []

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.title("ğŸ•¹ï¸ ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«")
    st.subheader("1. è³‡æ–™ã®è¿½åŠ ")
    uploaded_files = st.file_uploader(
        "ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°", 
        type=["pdf", "docx", "txt", "md", "csv", "xlsx", "png", "jpg", "jpeg"], 
        accept_multiple_files=True
    )
    st.markdown("---")

    with st.expander("âš™ï¸ è¨­å®š (APIãƒ»ãƒ¢ãƒ‡ãƒ«)", expanded=False):
        # APIã‚­ãƒ¼å…¥åŠ›
        st.text_input(
            "Google API Key", 
            type="password", 
            key="user_api_input",
            help="å…¥åŠ›ãŒãªã„å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã®ã‚­ãƒ¼ãŒä½¿ç”¨ã•ã‚Œã¾ã™"
        )
        
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        selected_model = st.selectbox(
            "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
            ["models/gemini-3-flash-preview"],
            index=0,
            help="Flash: é«˜é€Ÿãƒ»è»½é‡ / Pro: é«˜æ€§èƒ½"
        )

        st.caption("AIã®å½¹å‰²")
        system_prompt = st.text_area("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ", value="ã‚ãªãŸã¯è³‡æ–™ã«åŸºã¥ãå›ç­”ã™ã‚‹AIã§ã™ã€‚", height=100)

    # æœ‰åŠ¹ãªAPIã‚­ãƒ¼ã‚’å–å¾—
    active_api_key = get_api_key()
    
    if not active_api_key:
        st.error("ğŸ‘ˆ APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
        st.stop()

    try:
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’æ¸¡ã™
        llm = get_llm_model(active_api_key, selected_model)
        embed_model = get_embed_model(active_api_key)
        Settings.llm = llm
        Settings.embed_model = embed_model
    except Exception as e:
        st.error(f"ãƒ¢ãƒ‡ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()

    st.subheader("2. ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")
    c1, c2, c3 = st.columns(3)
    with c1:
        if st.button("ğŸ“", help="è¦ç´„", use_container_width=True):
            if st.session_state.messages:
                hist = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])
                st.session_state.summary_result = llm.complete(f"è¦ç´„ã—ã¦:\n{hist}").text
    with c2:
        if st.button("ğŸ—‘ï¸", help="ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.messages = []
            st.session_state.last_source_nodes = []
            if "summary_result" in st.session_state: del st.session_state.summary_result
            st.rerun()
    with c3:
        chat_log = ""
        for m in st.session_state.messages: chat_log += f"[{m['role']}] {m['content']}\n\n"
        if "summary_result" in st.session_state: chat_log += f"\n--- Summary ---\n{st.session_state.summary_result}"
        st.download_button("ğŸ’¾", data=chat_log, file_name=f"log_{datetime.datetime.now().strftime('%Y%m%d')}.txt", use_container_width=True)
    
    if "summary_result" in st.session_state:
        st.success(st.session_state.summary_result)

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
if uploaded_files:
    col1, col2 = st.columns([1, 1])

    # å³ã‚«ãƒ©ãƒ ï¼šãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ (ui.py)
    with col2:
        ui.display_file_preview(uploaded_files)

    # å·¦ã‚«ãƒ©ãƒ ï¼šãƒãƒ£ãƒƒãƒˆ
    with col1:
        st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]):
                st.markdown(msg["content"])
        
        if st.session_state.last_source_nodes:
            with st.expander("ğŸ” å‚ç…§ã‚½ãƒ¼ã‚¹ã‚’ç¢ºèª"):
                for node in st.session_state.last_source_nodes:
                    st.info(f"{node.metadata.get('file_name')} (Score: {node.score:.2f})\n{node.text[:100]}...")

    # --- ãƒãƒ£ãƒƒãƒˆå…¥åŠ›æ¬„ ---
    if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        try:
            # logic.py ã§å‡¦ç†
            index, extracted_images = logic.process_uploaded_files(uploaded_files)
            st.session_state.current_images = extracted_images
            retriever = index.as_retriever(similarity_top_k=5)

            nodes = retriever.retrieve(prompt)
            context_text = "\n\n".join([n.text for n in nodes])
            st.session_state.last_source_nodes = nodes

            final_prompt = (
                f"{system_prompt}\n"
                f"å‚è€ƒè³‡æ–™ã¨ç”»åƒ(ã‚ã‚Œã°)ã‚’è¦‹ã¦å›ç­”ã—ã¦ãã ã•ã„ã€‚\n"
                f"--- å‚è€ƒè³‡æ–™ ---\n{context_text}\n"
                f"--- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå• ---\n{prompt}"
            )

            image_docs = []
            if st.session_state.current_images:
                for img in st.session_state.current_images:
                    img_byte_arr = io.BytesIO()
                    img.save(img_byte_arr, format='PNG')
                    image_docs.append(ImageDocument(image=img_byte_arr.getvalue()))

            if image_docs:
                response = llm.complete(final_prompt, image_documents=image_docs)
            else:
                response = llm.complete(final_prompt)

            st.session_state.messages.append({"role": "assistant", "content": response.text})
            st.rerun()

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

else:
    st.info("ğŸ‘ˆ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰è³‡æ–™ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")