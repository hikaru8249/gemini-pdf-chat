import streamlit as st
import os
import tempfile
import base64
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings
from llama_index.llms.gemini import Gemini
from llama_index.embeddings.gemini import GeminiEmbedding
from dotenv import load_dotenv

# 1. ç’°å¢ƒè¨­å®š
load_dotenv()
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆãƒ¯ã‚¤ãƒ‰ãƒ¢ãƒ¼ãƒ‰ï¼‰
st.set_page_config(page_title="å¤šæ©Ÿèƒ½ PDF RAG Chat", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– å¤šæ©Ÿèƒ½ PDF RAG Chatbot")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("âš™ï¸ è¨­å®š")

# APIã‚­ãƒ¼å…¥åŠ›
if not GOOGLE_API_KEY:
    GOOGLE_API_KEY = st.sidebar.text_input("Google API Key", type="password")

if not GOOGLE_API_KEY:
    st.warning("APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# ãƒ¢ãƒ‡ãƒ«è¨­å®š
try:
    Settings.llm = Gemini(
        model="models/gemini-3-flash-preview", 
        api_key=GOOGLE_API_KEY, 
        temperature=0.3
    )
    Settings.embed_model = GeminiEmbedding(
        model_name="models/text-embedding-004", 
        api_key=GOOGLE_API_KEY
    )
except Exception as e:
    st.error(f"ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
    st.stop()

# ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
st.sidebar.subheader("ğŸ“ AIã¸ã®æŒ‡ç¤º")
system_prompt = st.sidebar.text_area(
    "AIã®å½¹å‰²",
    value="ã‚ãªãŸã¯æä¾›ã•ã‚ŒãŸPDFã®å†…å®¹ã«åŸºã¥ã„ã¦ç­”ãˆã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
    height=100
)

# --- é–¢æ•°å®šç¾© ---

def display_pdf(uploaded_file):
    bytes_data = uploaded_file.getvalue()
    base64_pdf = base64.b64encode(bytes_data).decode('utf-8')
    pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="600" type="application/pdf"></iframe>'
    st.markdown(pdf_display, unsafe_allow_html=True)

@st.cache_resource(show_spinner=False)
def create_index_from_uploaded_file(uploaded_file):
    with st.spinner("ğŸš€ AIãŒPDFã‚’èª­ã‚“ã§å­¦ç¿’ä¸­..."):
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            tmp_path = tmp_file.name

        documents = SimpleDirectoryReader(input_files=[tmp_path]).load_data()
        index = VectorStoreIndex.from_documents(documents)
        os.remove(tmp_path)
        return index

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---

col1, col2 = st.columns([1, 1])

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "messages" not in st.session_state:
    st.session_state.messages = []

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
with col1:
    uploaded_file = st.file_uploader("PDFã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["pdf"])

if uploaded_file:
    # å³ã‚«ãƒ©ãƒ ï¼šPDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    with col2:
        st.subheader("ğŸ“„ PDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
        display_pdf(uploaded_file)

    # å·¦ã‚«ãƒ©ãƒ ï¼šãƒãƒ£ãƒƒãƒˆå‡¦ç†
    with col1:
        st.subheader("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆ")
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
        try:
            index = create_index_from_uploaded_file(uploaded_file)
            query_engine = index.as_query_engine()

            # 1. éå»ã®ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã™ã¹ã¦è¡¨ç¤º
            for message in st.session_state.messages:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

            # 2. æœ€æ–°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒã€Œãƒ¦ãƒ¼ã‚¶ãƒ¼ã€ãªã‚‰ã€AIãŒå›ç­”ã‚’ç”Ÿæˆã™ã‚‹ï¼ˆã“ã“ãŒãƒã‚¤ãƒ³ãƒˆï¼‰
            if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
                with st.chat_message("assistant"):
                    # â˜…ã“ã“ã§ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤ºï¼ˆè€ƒãˆä¸­...ï¼‰
                    with st.spinner("AIãŒæ€è€ƒä¸­..."):
                        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®çµåˆ
                        last_user_msg = st.session_state.messages[-1]["content"]
                        final_prompt = f"{system_prompt}\n\n---\nãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {last_user_msg}"
                        
                        # å›ç­”ç”Ÿæˆ
                        response = query_engine.query(final_prompt)
                        st.markdown(response.response)
                
                # å›ç­”ã‚’å±¥æ­´ã«è¿½åŠ 
                st.session_state.messages.append({"role": "assistant", "content": response.response})

            # 3. å…¥åŠ›æ¬„ï¼ˆå¸¸ã«ä¸€ç•ªä¸‹ã«é…ç½®ï¼‰
            if prompt := st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„..."):
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’å±¥æ­´ã«è¿½åŠ ã—ã¦ã€ã™ãã«å†èª­ã¿è¾¼ã¿(rerun)ã™ã‚‹
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.rerun()

        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")